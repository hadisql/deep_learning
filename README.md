# **Neural Networks from Scratch**
---
### These notebooks explore Neural Networks, from the very basic Perceptron and its ability to classify linearly, to a DNN. All "from scratch", based on awesome tutorials from Guillaume Saint-Cirgue (Machine Learnia youtube channel) and more.<br></br>

### 1. Basic Perceptron (`DL_basics_1neuron.ipynb`)
### 2. Neural Network with 1 hidden layer (`DL_2layers.ipynb`)
### 3. Neural Network with 1 hidden layer and a multiclass output - softmax activation function (`DL_2layers_multiclass.ipynb`)
### 4. Neural Network with N hidden layers (`DL_Nlayers.ipynb`)<br></br>
## **Sources** :
<h3>

- for the mathematical notations and equations :
  - [Machine Learnia's Youtube channel, deeplearning playlist](https://www.youtube.com/watch?v=XUFLq6dKQok&list=PLO_fdPEVlfKoanjvTJbIbd9V5d9Pzp8Rw)

- for the multiclass classification :
  I based the `DL_2layers_multiclass` notebook on previous notebooks (`DL_basics_1neuron` & `DL_2layers`) and different sources from internet :
    - [an example of multiclass DNN python code](https://stackabuse.com/creating-a-neural-network-from-scratch-in-python-multi-class-classification/)
    - [Detailed equations & python code](http://kkms.org/index.php/kjm/article/view/1275/673)
    - [Cross-Entropy calculation](https://stats.stackexchange.com/questions/378274/how-to-construct-a-cross-entropy-loss-for-general-regression-targets)
    - [Courses notes on deeplearning](https://physique.cmaisonneuve.qc.ca/svezina/mat/note_mat/MAT_Chap%206.2.pdf)

</h3>
